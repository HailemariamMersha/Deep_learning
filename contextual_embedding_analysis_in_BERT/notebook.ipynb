{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HailemariamMersha/NYU-DLFL25U/blob/context_embedding/projects/contextual_cmbedding_analysis_in_BERT/new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CLgiQZp4dHat",
      "metadata": {
        "id": "CLgiQZp4dHat"
      },
      "source": [
        "\n",
        "## Contextual Embedding Analysis in BERT\n",
        "\n",
        "**Abstract:**  \n",
        "This project investigates how contextual meaning is computed in transformer language models. Using the ambiguous token “rose,” I compare its embeddings across BERT layers in flower and verb contexts. Embeddings remain similar in early layers but diverge in deeper layers, consistent with increasing contextualization. To quantify contextual variation, we compared embeddings using cosine similarity, which measures directional alignment in high-dimensional space. We observed that tokens sharing semantic roles tend to have higher similarity than tokens sharing only surface form, supporting our hypothesis that BERT encodes meaning dynamically rather than storing a single representation per word type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uRRU36xJdHao",
      "metadata": {
        "id": "uRRU36xJdHao"
      },
      "source": [
        "\n",
        "### BERT contextual embeddings\n",
        "For an input token sequence $x_{1:T}$, BERT produces layer-wise hidden states:\n",
        "$$\n",
        "H^{(\\ell)} = [h_1^{(\\ell)}, h_2^{(\\ell)}, \\dots, h_T^{(\\ell)}] \\in \\mathbb{R}^{T \\times d},\n",
        "\\quad \\ell=0,1,\\dots,L\n",
        "$$\n",
        "where $h_t^{(\\ell)}$ is the contextual embedding of token $t$ at layer $\\ell$.\n",
        "\n",
        "### Similarity\n",
        "Given two embeddings $u, v \\in \\mathbb{R}^d$, cosine similarity is\n",
        "$$\n",
        "\\cos(u,v) = \\frac{u^\\top v}{\\|u\\|\\|v\\|}.\n",
        "$$\n",
        "We will track $\\cos(h_{t_A}^{(\\ell)}, h_{t_B}^{(\\ell)})$ across layers $\\ell$ for the token “rose” in different contexts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gb_21XDUdHao",
      "metadata": {
        "id": "gb_21XDUdHao"
      },
      "source": [
        "## Experimental Design\n",
        "\n",
        "- use a pretrained BERT model from Hugging face,\n",
        "- extract hidden states for all layers,\n",
        "- extract attention weights,\n",
        "- run small controlled experiments,\n",
        "- visualize results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bJynmUmdHao",
      "metadata": {
        "id": "1bJynmUmdHao"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g_1VVo-hdHap",
      "metadata": {
        "id": "g_1VVo-hdHap"
      },
      "source": [
        "## 1) Load BERT\n",
        "\n",
        "We use BERT as a frozen feature extractor.\n",
        "\n",
        "We need:\n",
        "- hidden states (all 12 layers),\n",
        "- attentions (all 12 layers),\n",
        "so we enable `output_hidden_states=True` and `output_attentions=True` in the forward pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5XcSmq1idHap",
      "metadata": {
        "collapsed": true,
        "id": "5XcSmq1idHap"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "saJAFxXrdHap",
      "metadata": {
        "id": "saJAFxXrdHap"
      },
      "source": [
        "## 2) Helper functions\n",
        "\n",
        "We implement small, transparent utilities:\n",
        "1. cosine similarity\n",
        "2. run BERT and extract hidden states + attentions\n",
        "3. locate “rose” token index safely\n",
        "4. compute layer-wise similarity trajectory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hbS0riG3dHap",
      "metadata": {
        "id": "hbS0riG3dHap"
      },
      "source": [
        "### 2.1 Cosine similarity\n",
        "$$\n",
        "\\cos(u,v)=\\frac{u^\\top v}{\\|u\\|\\|v\\|}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fCbRjIz2dHaq",
      "metadata": {
        "id": "fCbRjIz2dHaq"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(u, v, eps=1e-12):\n",
        "    u, v = np.array(u), np.array(v)\n",
        "    dot = np.dot(u, v)\n",
        "    norm = np.linalg.norm(u) * np.linalg.norm(v)\n",
        "    return dot / (norm + eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YjHgEHVGdHaq",
      "metadata": {
        "id": "YjHgEHVGdHaq"
      },
      "source": [
        "### 2.2 Run BERT and extract hidden states + attentions\n",
        "\n",
        "Returns:\n",
        "- tokens: list of token strings\n",
        "- hidden_states_np: list of arrays (T, d) for layers 0..L\n",
        "- attentions_np: list of arrays (H, T, T) for layers 1..L\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_cEo-fmbdHaq",
      "metadata": {
        "id": "_cEo-fmbdHaq"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_bert(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
        "    outputs = model(**inputs, output_hidden_states=True, output_attentions=True)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].tolist())\n",
        "    hidden_states = [h[0].cpu().numpy() for h in outputs.hidden_states]\n",
        "    attentions = [a[0].cpu().numpy() for a in outputs.attentions]\n",
        "\n",
        "    return tokens, hidden_states, attentions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cnyAESj5dHaq",
      "metadata": {
        "id": "cnyAESj5dHaq"
      },
      "source": [
        "### 2.3 Find the token index for \"rose\" (WordPiece-safe)\n",
        "\n",
        "BERT tokenizes into WordPieces. We search for token == \"rose\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hziIVGI_dHaq",
      "metadata": {
        "id": "hziIVGI_dHaq"
      },
      "outputs": [],
      "source": [
        "def find_token_index(tokens, target_token=\"rose\", occurrence=0):\n",
        "    \"\"\"Find the index of the target token in the list.\"\"\"\n",
        "    indices = [i for i, t in enumerate(tokens) if t == target_token]\n",
        "    if not indices or occurrence >= len(indices):\n",
        "        raise ValueError(f\"Token '{target_token}' (occ {occurrence}) not found in {tokens}\")\n",
        "    return indices[occurrence]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Lq8AE4iBdHaq",
      "metadata": {
        "id": "Lq8AE4iBdHaq"
      },
      "source": [
        "### 2.4 Layer trajectory of “rose” similarity\n",
        "\n",
        "$$\n",
        "s^{(\\ell)} = \\cos(r_A^{(\\ell)}, r_B^{(\\ell)}).\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lZIpLLXAdHaq",
      "metadata": {
        "id": "lZIpLLXAdHaq"
      },
      "outputs": [],
      "source": [
        "def rose_similarity_trajectory(sentence_a, sentence_b, target_token=\"rose\"):\n",
        "    tok_a, hs_a, att_a = run_bert(sentence_a)\n",
        "    tok_b, hs_b, att_b = run_bert(sentence_b)\n",
        "\n",
        "    idx_a = find_token_index(tok_a, target_token)\n",
        "    idx_b = find_token_index(tok_b, target_token)\n",
        "\n",
        "    sims = [\n",
        "        cosine_similarity(hs_a[layer][idx_a], hs_b[layer][idx_b])\n",
        "        for layer in range(len(hs_a))\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"tokens_a\": tok_a, \"tokens_b\": tok_b,\n",
        "        \"idx_a\": idx_a, \"idx_b\": idx_b,\n",
        "        \"hs_a\": hs_a, \"hs_b\": hs_b,\n",
        "        \"att_a\": att_a, \"att_b\": att_b,\n",
        "        \"sims\": np.array(sims),\n",
        "        \"sentence_a\": sentence_a, \"sentence_b\": sentence_b\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hAr42i0z3ASm",
      "metadata": {
        "id": "hAr42i0z3ASm"
      },
      "source": [
        "### 2.5 Extract layer-wise embeddings for a specific token from a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df06a2ff",
      "metadata": {
        "id": "df06a2ff"
      },
      "outputs": [],
      "source": [
        "def extract_layerwise_embeddings(sentence, target_token=\"rose\", occurrence=0):\n",
        "    tokens, hidden_states, _ = run_bert(sentence)\n",
        "    token_idx = find_token_index(tokens, target_token, occurrence)\n",
        "\n",
        "    layerwise_embeddings = [\n",
        "        hs[token_idx] for hs in hidden_states\n",
        "    ]\n",
        "    return layerwise_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a115bba",
      "metadata": {
        "id": "7a115bba"
      },
      "source": [
        "## Verb-vs-Flower Analysis\n",
        "\n",
        "### Hypothesis\n",
        "BERT embeddings for the ambiguous token 'rose' will dynamically diverge across layers when presented in sentences emphasizing different senses (flower vs. verb). Specifically, within-sense similarities (flower-flower or verb-verb) will remain high or increase, while between-sense similarities (flower-verb) will decrease in deeper layers, indicating contextual disambiguation.\n",
        "\n",
        "### Predictions\n",
        "- **Prediction 1 (Flower-Flower Similarity):** Cosine similarity between 'rose' embeddings from two flower-context sentences will remain high and stable, or even slightly increase, across layers.\n",
        "- **Prediction 2 (Verb-Verb Similarity):** Cosine similarity between 'rose' embeddings from two verb-context sentences will remain high and stable, or even slightly increase, across layers.\n",
        "- **Prediction 3 (Flower-Verb Similarity):** Cosine similarity between 'rose' embeddings from a flower-context sentence and a verb-context sentence will start relatively high in early layers and decrease significantly in deeper layers.\n",
        "\n",
        "### Rationale for Sentence Design\n",
        "To rigorously test this hypothesis, we have meticulously crafted pairs of sentences that clearly disambiguate the 'rose' token into either its noun (flower) or verb sense. Each sentence is designed to provide sufficient context to bias BERT towards one specific meaning. This controlled experimental setup allows us to observe and quantify the layer-wise evolution of semantic distinction within BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXmjpraBdHar",
      "metadata": {
        "id": "eXmjpraBdHar"
      },
      "outputs": [],
      "source": [
        "\n",
        "pairs = [\n",
        "    (\"I gave my mom a rose.\", \"The sun rose at dawn.\"),\n",
        "    (\"She smelled the rose in the garden.\", \"The balloon rose into the sky.\"),\n",
        "    (\"He watered the rose every morning.\", \"Prices rose after the announcement.\"),\n",
        "    (\"The rose was red and beautiful.\", \"The temperature rose quickly today.\"),\n",
        "]\n",
        "\n",
        "focus_a = \"I gave my mom a rose.\"\n",
        "focus_b = \"The sun rose at dawn.\"\n",
        "\n",
        "flower_sentences = [\n",
        "    \"I gave my mom a rose.\",\n",
        "    \"She smelled the rose in the garden.\",\n",
        "    \"He watered the rose every morning.\",\n",
        "    \"The rose was red and beautiful.\"\n",
        "]\n",
        "\n",
        "verb_sentences = [\n",
        "    \"The sun rose at dawn.\",\n",
        "    \"The balloon rose into the sky.\",\n",
        "    \"Prices rose after the announcement.\",\n",
        "    \"The temperature rose quickly today.\"\n",
        "]\n",
        "\n",
        "all_sentences = flower_sentences + verb_sentences\n",
        "\n",
        "sense_labels = [\"flower\"] * len(flower_sentences) + [\"verb\"] * len(verb_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m_9vDNya3jfv",
      "metadata": {
        "id": "m_9vDNya3jfv"
      },
      "source": [
        "## 3) Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0903bac",
      "metadata": {
        "id": "d0903bac"
      },
      "source": [
        "## Extract All Layer-wise Embeddings\n",
        "\n",
        "Extract layer-wise embeddings for the 'rose' token from each sentence in `all_sentences` and store them in a single tensor `E` (N, L, D).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4273bda0",
      "metadata": {
        "id": "4273bda0"
      },
      "outputs": [],
      "source": [
        "all_embeddings_list = []\n",
        "\n",
        "for sentence in all_sentences:\n",
        "    layerwise_embs = extract_layerwise_embeddings(sentence, target_token=\"rose\")\n",
        "    all_embeddings_list.append(layerwise_embs)\n",
        "E = np.array(all_embeddings_list)\n",
        "\n",
        "print(f\"Shape of E (num_sentences, num_layers, embedding_dim): {E.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da4a020",
      "metadata": {
        "id": "9da4a020"
      },
      "outputs": [],
      "source": [
        "num_sentences = E.shape[0]\n",
        "num_layers = E.shape[1]\n",
        "\n",
        "layerwise_similarities = np.zeros((num_layers, num_sentences, num_sentences))\n",
        "\n",
        "for layer in range(num_layers):\n",
        "    for i in range(num_sentences):\n",
        "        for j in range(num_sentences):\n",
        "            # E[i, layer] gives the 'rose' embedding for sentence i at the current layer\n",
        "            # E[j, layer] gives the 'rose' embedding for sentence j at the current layer\n",
        "            layerwise_similarities[layer, i, j] = cosine_similarity(E[i, layer], E[j, layer])\n",
        "\n",
        "print(f\"Shape of layerwise_similarities (num_layers, num_sentences, num_sentences): {layerwise_similarities.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d3803f",
      "metadata": {
        "id": "20d3803f"
      },
      "outputs": [],
      "source": [
        "num_layers = E.shape[1]\n",
        "print(num_layers)\n",
        "flower_indices = [i for i, label in enumerate(sense_labels) if label == \"flower\"]\n",
        "verb_indices = [i for i, label in enumerate(sense_labels) if label == \"verb\"]\n",
        "\n",
        "flower_flower_sims_mean = []\n",
        "flower_flower_sims_min = []\n",
        "flower_flower_sims_max = []\n",
        "\n",
        "verb_verb_sims_mean = []\n",
        "verb_verb_sims_min = []\n",
        "verb_verb_sims_max = []\n",
        "\n",
        "flower_verb_sims_mean = []\n",
        "flower_verb_sims_min = []\n",
        "flower_verb_sims_max = []\n",
        "\n",
        "for layer in range(num_layers):\n",
        "    current_layer_sim_matrix = layerwise_similarities[layer]\n",
        "\n",
        "    ff_layer_sims = []\n",
        "    for i in flower_indices:\n",
        "        for j in flower_indices:\n",
        "            if i != j:\n",
        "                ff_layer_sims.append(current_layer_sim_matrix[i, j])\n",
        "    flower_flower_sims_mean.append(np.mean(ff_layer_sims) if ff_layer_sims else 0)\n",
        "    flower_flower_sims_min.append(np.min(ff_layer_sims) if ff_layer_sims else 0)\n",
        "    flower_flower_sims_max.append(np.max(ff_layer_sims) if ff_layer_sims else 0)\n",
        "\n",
        "    vv_layer_sims = []\n",
        "    for i in verb_indices:\n",
        "        for j in verb_indices:\n",
        "            if i != j:\n",
        "                vv_layer_sims.append(current_layer_sim_matrix[i, j])\n",
        "    verb_verb_sims_mean.append(np.mean(vv_layer_sims) if vv_layer_sims else 0)\n",
        "    verb_verb_sims_min.append(np.min(vv_layer_sims) if vv_layer_sims else 0)\n",
        "    verb_verb_sims_max.append(np.max(vv_layer_sims) if vv_layer_sims else 0)\n",
        "\n",
        "    fv_layer_sims = []\n",
        "    for i in flower_indices:\n",
        "        for j in verb_indices:\n",
        "            fv_layer_sims.append(current_layer_sim_matrix[i, j])\n",
        "    flower_verb_sims_mean.append(np.mean(fv_layer_sims) if fv_layer_sims else 0)\n",
        "    flower_verb_sims_min.append(np.min(fv_layer_sims) if fv_layer_sims else 0)\n",
        "    flower_verb_sims_max.append(np.max(fv_layer_sims) if fv_layer_sims else 0)\n",
        "print(flower_flower_sims_max)\n",
        "print(flower_flower_sims_mean)\n",
        "print(flower_flower_sims_min)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(flower_flower_sims_mean, label='Flower-Flower Similarity (Mean)', marker='o', linestyle='-')\n",
        "plt.fill_between(range(num_layers), flower_flower_sims_min, flower_flower_sims_max, color='blue', alpha=0.1, label='Flower-Flower (Min/Max)')\n",
        "\n",
        "plt.plot(verb_verb_sims_mean, label='Verb-Verb Similarity (Mean)', marker='x', linestyle='--')\n",
        "plt.fill_between(range(num_layers), verb_verb_sims_min, verb_verb_sims_max, color='orange', alpha=0.1, label='Verb-Verb (Min/Max)')\n",
        "\n",
        "plt.plot(flower_verb_sims_mean, label='Flower-Verb Similarity (Mean)', marker='s', linestyle='-.')\n",
        "plt.fill_between(range(num_layers), flower_verb_sims_min, flower_verb_sims_max, color='green', alpha=0.1, label='Flower-Verb (Min/Max)')\n",
        "\n",
        "plt.xlabel('Layer')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.title(\"Layer-wise 'Rose' Embedding Similarities (Flower vs. Verb Contexts)\")\n",
        "plt.legend(fontsize=8)\n",
        "plt.grid(True)\n",
        "plt.xticks(range(num_layers))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb69b9a6",
      "metadata": {
        "id": "bb69b9a6"
      },
      "source": [
        "### Results — Verb-vs-Flower Analysis\n",
        "\n",
        "- **Observation:** The plot clearly shows three distinct trajectories for cosine similarity across BERT's layers.\n",
        "    - **Flower-Flower Similarity (solid blue line):** This trajectory starts high (around 0.95) and remains relatively high and stable, decreasing only slightly in deeper layers (around 0.78).\n",
        "    - **Verb-Verb Similarity (dashed orange line):** Similar to flower-flower, this trajectory also starts high (around 0.98) and stays consistently high, with a slight decrease in deeper layers (around 0.61).\n",
        "    - **Flower-Verb Similarity (dash-dot green line):** This trajectory starts moderately high (around 0.95), similar to the within-sense similarities, but drops significantly and consistently across layers, reaching a much lower value (around 0.39) in the deepest layers.\n",
        "\n",
        "- **Interpretation:** These results strongly support the hypothesis and predictions.\n",
        "    - **Prediction 1 & 2 (Flower-Flower & Verb-Verb Stability):** The high and stable (or slightly decreasing) similarities within the same semantic sense (flower-flower and verb-verb) indicate that BERT maintains consistent representations for 'rose' when its context consistently implies the same meaning. The slight decrease might be attributed to the model refining finer contextual nuances even within the same broad sense.\n",
        "    - **Prediction 3 (Flower-Verb Divergence):** The significant and consistent divergence of the flower-verb similarity in deeper layers demonstrates that BERT actively disambiguates the meaning of 'rose' based on its context. In early layers, the embeddings are more general, leading to higher similarity even between different senses. However, as information propagates through the layers, BERT incorporates contextual cues to differentiate the specific meaning of 'rose', pushing the embeddings for different senses further apart. This confirms that BERT dynamically computes and refines word meaning to reflect context-dependent interpretations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0df8d1",
      "metadata": {
        "id": "6f0df8d1"
      },
      "source": [
        "## Generate Final-Layer Similarity Heatmap\n",
        "\n",
        "A similarity matrix for the 'rose' embeddings at the final layer (or average of top few layers) across all sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c657b5da",
      "metadata": {
        "id": "c657b5da"
      },
      "outputs": [],
      "source": [
        "final_layer_embeddings = E[:, -1, :]\n",
        "final_layer_sim_matrix = np.zeros((num_sentences, num_sentences))\n",
        "for i in range(num_sentences):\n",
        "    for j in range(num_sentences):\n",
        "        final_layer_sim_matrix[i, j] = cosine_similarity(final_layer_embeddings[i], final_layer_embeddings[j])\n",
        "\n",
        "\n",
        "sentence_labels = [f\"{label} ({s[:20]}...)\" for label, s in zip(sense_labels, all_sentences)]\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    final_layer_sim_matrix,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"viridis\",\n",
        "    xticklabels=sentence_labels,\n",
        "    yticklabels=sentence_labels\n",
        ")\n",
        "\n",
        "plt.title(\"Final Layer 'Rose' Embedding Similarity Heatmap (Clustering by Sense)\")\n",
        "plt.xlabel(\"Sentence Context\")\n",
        "plt.ylabel(\"Sentence Context\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7c4f5c",
      "metadata": {
        "id": "4b7c4f5c"
      },
      "source": [
        "### Results — Final Layer Similarity Heatmap\n",
        "\n",
        "- **Observation:** The heatmap visually confirms the findings from the layer-wise similarity plots. There are clear blocks of high similarity (darker colors, values close to 1.0) along the diagonal corresponding to within-sense comparisons:\n",
        "    - The top-left 4x4 block (flower-flower comparisons) shows high similarity values.\n",
        "    - The bottom-right 4x4 block (verb-verb comparisons) also shows high similarity values.\n",
        "    - Conversely, the off-diagonal blocks (top-right 4x4 and bottom-left 4x4), representing flower-verb comparisons, show significantly lower similarity values (lighter colors, values closer to 0.4), indicating strong dissimilarity.\n",
        "\n",
        "- **Interpretation:** This heatmap provides a compelling visual summary of BERT's contextual disambiguation capabilities in its final layers. It demonstrates that by the last layer, BERT has successfully differentiated the 'rose' embeddings such that those from flower contexts are highly similar to each other, and those from verb contexts are highly similar to each other. Crucially, the embeddings for 'rose' from different senses (flower vs. verb) are distinctly dissimilar. This strong clustering of embeddings by semantic sense in the final layer underscores that BERT does not merely store fixed word meanings but actively processes and refines them into distinct contextual representations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nIYBCSyfodEC",
      "metadata": {
        "id": "nIYBCSyfodEC"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "In this notebook, we investigated how BERT represents words in context by analyzing token-level embeddings across different sentences. Unlike static word embeddings, BERT produces contextualized representations, meaning that the same surface word can have different vector representations depending on its surrounding context. Our experiments comparing embeddings of the same word used in different semantic roles (e.g., noun vs. verb) demonstrate this behavior clearly, as embeddings diverge when contextual meaning changes.\n",
        "\n",
        "To quantify contextual variation, we compared embeddings using cosine similarity, which measures directional alignment in high-dimensional space. We observed that tokens sharing semantic roles tend to have higher similarity than tokens sharing only surface form, supporting our hypothesis that BERT encodes meaning dynamically rather than storing a single representation per word type.\n",
        "\n",
        "It is important to note that BERT operates on WordPiece tokens rather than full words. While some words correspond to a single token, others may be split into multiple subword units. In such cases, token-level embeddings must be aggregated (e.g., via averaging or selecting the first subword) to form a word-level representation. This tokenization mechanism is fundamental to how BERT represents language and should be considered when interpreting embedding similarities.\n",
        "\n",
        "Additionally, variation in embeddings is influenced not only by semantic context but also by positional encodings and sentence-level structure. As a result, differences in embeddings should be interpreted as reflecting a combination of semantic, syntactic, and positional factors, rather than meaning alone. Furthermore, cosine similarity captures overall closeness between representations but does not identify which specific linguistic features (e.g., tense, syntactic role, or sense) are responsible for the observed differences.\n",
        "\n",
        "Finally, our analysis focuses on embeddings extracted from a fixed pretrained BERT model. Fine-tuning on downstream tasks would likely reshape these representations, emphasizing task-relevant features while potentially reducing general semantic distinctions. Despite these limitations, the results provide clear evidence that BERT computes word meaning contextually at inference time, producing flexible representations that adapt to usage rather than relying on static word vectors.\n",
        "\n",
        "\n",
        "Overall, this analysis highlights how contextual embedding models like BERT move beyond surface-level lexical representations and instead encode language as a function of both meaning and context, which is central to their success in modern NLP tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
